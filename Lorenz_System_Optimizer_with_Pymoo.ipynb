{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pymoo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-xE_GVVLrnP",
        "outputId": "08b3bc8c-5a48-4b9a-ca81-17d285e5f367"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymoo in /usr/local/lib/python3.12/dist-packages (0.6.1.5)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.12/dist-packages (from pymoo) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.12/dist-packages (from pymoo) (1.16.2)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.12/dist-packages (from pymoo) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.4 in /usr/local/lib/python3.12/dist-packages (from pymoo) (1.8.0)\n",
            "Requirement already satisfied: cma>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from pymoo) (4.4.0)\n",
            "Requirement already satisfied: alive-progress in /usr/local/lib/python3.12/dist-packages (from pymoo) (3.3.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from pymoo) (0.3.8)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.12/dist-packages (from pymoo) (1.2.18)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (2.9.0.post0)\n",
            "Requirement already satisfied: about-time==4.2.1 in /usr/local/lib/python3.12/dist-packages (from alive-progress->pymoo) (4.2.1)\n",
            "Requirement already satisfied: graphemeu==0.7.2 in /usr/local/lib/python3.12/dist-packages (from alive-progress->pymoo) (0.7.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.12/dist-packages (from Deprecated->pymoo) (1.17.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3->pymoo) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import math\n",
        "import copy\n",
        "import warnings\n",
        "\n",
        "# Suppress matplotlib warnings for cleaner output during optimization\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
        "\n",
        "# --- Pymoo Imports ---\n",
        "from pymoo.core.problem import Problem\n",
        "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
        "from pymoo.operators.crossover.sbx import SBX\n",
        "from pymoo.operators.mutation.pm import PM\n",
        "from pymoo.operators.sampling.rnd import FloatRandomSampling\n",
        "from pymoo.termination import get_termination\n",
        "from pymoo.optimize import minimize\n",
        "\n",
        "\n",
        "# Set device to GPU if available, otherwise CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "#region ----------------- Model Architecture -----------------\n",
        "class ChebySigmoidActivation(nn.Module):\n",
        "    def __init__(self, alpha=1.0, beta=1.0, n=1.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.n = n\n",
        "\n",
        "    def get_n_value(self):\n",
        "        return self.n\n",
        "\n",
        "    def forward(self, x):\n",
        "        sigmoid_val = torch.sigmoid(x)\n",
        "        tanh_beta_val = torch.tanh(self.beta * x)\n",
        "        safe_tanh_beta_val = torch.clamp(tanh_beta_val, -1 + 1e-6, 1 - 1e-6)\n",
        "        out = sigmoid_val + self.alpha * torch.cos(self.n * torch.acos(safe_tanh_beta_val)) * sigmoid_val * (1 - sigmoid_val)\n",
        "        return out\n",
        "\n",
        "class ChebyTanhActivation(nn.Module):\n",
        "    def __init__(self, alpha=1.0, beta=1.0, n=1.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.n = n\n",
        "\n",
        "    def get_n_value(self):\n",
        "        return self.n\n",
        "\n",
        "    def forward(self, x):\n",
        "        tanh_beta_val = torch.tanh(self.beta * x)\n",
        "        tanh_val = torch.tanh(x)\n",
        "        sech_val = (1 / torch.cosh(x)) ** 2\n",
        "        safe_tanh_beta_val = torch.clamp(tanh_beta_val, -1 + 1e-6, 1 - 1e-6)\n",
        "        out = tanh_val + self.alpha * torch.cos(self.n * torch.acos(safe_tanh_beta_val)) * sech_val\n",
        "        return out\n",
        "\n",
        "class CustomLSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, alpha=1.0, beta=1.0, n=1.0):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.weight_ih = nn.Parameter(torch.empty(4 * hidden_size, input_size))\n",
        "        self.weight_hh = nn.Parameter(torch.empty(4 * hidden_size, hidden_size))\n",
        "        self.bias_ih = nn.Parameter(torch.zeros(4 * hidden_size))\n",
        "        self.bias_hh = nn.Parameter(torch.zeros(4 * hidden_size))\n",
        "        self.sigmoid_activation = ChebySigmoidActivation(alpha=alpha, beta=beta, n=n)\n",
        "        self.tanh_activation = ChebyTanhActivation(alpha=alpha, beta=beta, n=n)\n",
        "\n",
        "    def forward(self, input, hx):\n",
        "        h_prev, c_prev = hx\n",
        "        gates = F.linear(input, self.weight_ih, self.bias_ih) + F.linear(h_prev, self.weight_hh, self.bias_hh)\n",
        "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, dim=1)\n",
        "        forgetgate = self.sigmoid_activation(forgetgate)\n",
        "        ingate = self.sigmoid_activation(ingate)\n",
        "        cellgate_candidate = self.tanh_activation(cellgate)\n",
        "        outgate = self.sigmoid_activation(outgate)\n",
        "        c_next = forgetgate * c_prev + ingate * cellgate_candidate\n",
        "        h_next = outgate * self.tanh_activation(c_next)\n",
        "        return h_next, (h_next, c_next)\n",
        "\n",
        "    def get_n_values(self):\n",
        "        return {\n",
        "            'sigmoid_n': self.sigmoid_activation.get_n_value(),\n",
        "            'tanh_n': self.tanh_activation.get_n_value()\n",
        "        }\n",
        "\n",
        "class CustomLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, alpha=1.0, beta=1.0, n=1.0):\n",
        "        super().__init__()\n",
        "        self.cell = CustomLSTMCell(input_size, hidden_size, alpha=alpha, beta=beta, n=n)\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    def forward(self, inputs, hx=None):\n",
        "        inputs = inputs.transpose(0, 1)\n",
        "        if hx is None:\n",
        "            batch_size = inputs.size(1)\n",
        "            h_0 = torch.zeros(batch_size, self.cell.hidden_size, device=inputs.device)\n",
        "            c_0 = torch.zeros(batch_size, self.cell.hidden_size, device=inputs.device)\n",
        "            hx = (h_0, c_0)\n",
        "        h, c = hx\n",
        "        outputs = []\n",
        "        for t in range(inputs.size(0)):\n",
        "            h, (h, c) = self.cell(inputs[t], (h, c))\n",
        "            outputs.append(h)\n",
        "        outputs = torch.stack(outputs).transpose(0, 1)\n",
        "        return outputs, (h, c)\n",
        "\n",
        "    def get_n_values(self):\n",
        "        return self.cell.get_n_values()\n",
        "\n",
        "class MultivariateLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=50, output_size=1, alpha=1.0, beta=1.0, n=1.0):\n",
        "        super().__init__()\n",
        "        self.lstm = CustomLSTM(input_size, hidden_size, alpha=alpha, beta=beta, n=n)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.linear = nn.Linear(hidden_size, output_size)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None: init.constant_(module.bias, 0)\n",
        "        elif isinstance(module, CustomLSTMCell):\n",
        "            init.xavier_uniform_(module.weight_ih)\n",
        "            init.xavier_uniform_(module.weight_hh)\n",
        "            init.constant_(module.bias_ih, 0)\n",
        "            init.constant_(module.bias_hh, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        last_output = self.dropout(lstm_out[:, -1, :])\n",
        "        predictions = self.linear(last_output)\n",
        "        return predictions\n",
        "\n",
        "    def get_n_values(self):\n",
        "        return self.lstm.get_n_values()\n",
        "#endregion\n",
        "\n",
        "#region ----------------- Data & Training Pipeline -----------------\n",
        "def create_multivariate_sequences(data, seq_length, feature_column_idx=None, target_column_idx=None):\n",
        "    xs, ys = [], []\n",
        "    if feature_column_idx is not None and not isinstance(feature_column_idx, list):\n",
        "        feature_column_idx = [feature_column_idx]\n",
        "    for i in range(len(data) - seq_length):\n",
        "        x = data[i:i+seq_length, feature_column_idx] if feature_column_idx is not None else data[i:i+seq_length]\n",
        "        y = data[i+seq_length, target_column_idx:target_column_idx+1] if target_column_idx is not None else data[i+seq_length]\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "def prepare_multivariate_data(data, seq_length=20, train_ratio=0.8, batch_size=32, feature_column_idx=None, target_column_idx=None):\n",
        "    if isinstance(data, pd.DataFrame):\n",
        "        data = data.values\n",
        "\n",
        "    n_features = data.shape[1]\n",
        "    input_size = len(feature_column_idx) if isinstance(feature_column_idx, list) else (1 if feature_column_idx is not None else n_features)\n",
        "    output_size = 1 if target_column_idx is not None else n_features\n",
        "\n",
        "    train_size = int(len(data) * train_ratio)\n",
        "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "    scaler.fit(data[:train_size])\n",
        "    data_scaled = scaler.transform(data)\n",
        "\n",
        "    X, y = create_multivariate_sequences(data_scaled, seq_length, feature_column_idx, target_column_idx)\n",
        "\n",
        "    X_train, X_test = X[:train_size-seq_length], X[train_size-seq_length:]\n",
        "    y_train, y_test = y[:train_size-seq_length], y[train_size-seq_length:]\n",
        "\n",
        "    X_train = torch.FloatTensor(X_train).to(device)\n",
        "    y_train = torch.FloatTensor(y_train).to(device)\n",
        "    X_test = torch.FloatTensor(X_test).to(device)\n",
        "    y_test = torch.FloatTensor(y_test).to(device)\n",
        "\n",
        "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return {\n",
        "        'train_loader': train_loader, 'test_loader': test_loader, 'scaler': scaler,\n",
        "        'X_train': X_train, 'y_train': y_train, 'X_test': X_test, 'y_test': y_test,\n",
        "        'input_size': input_size, 'output_size': output_size,\n",
        "        'target_column_idx': target_column_idx\n",
        "    }\n",
        "\n",
        "def train_model(model, train_loader, test_loader, epochs=100, learning_rate=0.001, verbose=True):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(X_batch)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        if verbose and (epoch + 1) % 10 == 0:\n",
        "            model.eval()\n",
        "            test_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for X_test_batch, y_test_batch in test_loader:\n",
        "                    y_pred_test = model(X_test_batch)\n",
        "                    test_loss += criterion(y_pred_test, y_test_batch).item()\n",
        "            test_loss /= len(test_loader)\n",
        "            print(f'Epoch {epoch+1}/{epochs}, Test Loss: {test_loss:.6f}')\n",
        "\n",
        "    # Final evaluation to get test RMSE\n",
        "    model.eval()\n",
        "    all_preds, all_true = [], []\n",
        "    with torch.no_grad():\n",
        "        for X_test_batch, y_test_batch in test_loader:\n",
        "            preds = model(X_test_batch).cpu().numpy()\n",
        "            true = y_test_batch.cpu().numpy()\n",
        "            all_preds.append(preds)\n",
        "            all_true.append(true)\n",
        "\n",
        "    test_rmse = sqrt(mean_squared_error(np.vstack(all_true), np.vstack(all_preds)))\n",
        "    return test_rmse\n",
        "\n",
        "def predict_all_data(model, data_dict):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_predictions_scaled = model(data_dict['X_test']).cpu().numpy()\n",
        "\n",
        "    scaler = data_dict['scaler']\n",
        "    target_idx = data_dict['target_column_idx']\n",
        "\n",
        "    dummy_array = np.zeros((test_predictions_scaled.shape[0], scaler.n_features_in_))\n",
        "    dummy_array[:, target_idx] = test_predictions_scaled.flatten()\n",
        "    test_predictions = scaler.inverse_transform(dummy_array)[:, target_idx]\n",
        "\n",
        "    return test_predictions\n",
        "\n",
        "def predict_and_visualize_multivariate(model, data_dict, title='Multivariate Time Series Forecasting'):\n",
        "    predictions = predict_all_data(model, data_dict)\n",
        "\n",
        "    # Get original, unscaled test data for comparison\n",
        "    scaler = data_dict['scaler']\n",
        "    y_test_numpy = data_dict['y_test'].cpu().numpy()\n",
        "    target_idx = data_dict['target_column_idx']\n",
        "\n",
        "    dummy_array_true = np.zeros((len(y_test_numpy), scaler.n_features_in_))\n",
        "    dummy_array_true[:, target_idx] = y_test_numpy.flatten()\n",
        "    actual = scaler.inverse_transform(dummy_array_true)[:, target_idx]\n",
        "\n",
        "    test_rmse = sqrt(mean_squared_error(actual, predictions))\n",
        "    print(f\"\\nFinal Test RMSE: {test_rmse:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.plot(actual, label='Actual Test Data', color='darkblue', alpha=0.7)\n",
        "    plt.plot(predictions, label='Predicted Test Data', color='red', linestyle='--')\n",
        "    plt.title(f'{title} - Test Set (RMSE: {test_rmse:.4f})')\n",
        "    plt.xlabel('Time Step')\n",
        "    plt.ylabel('Value')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return test_rmse\n",
        "\n",
        "def load_multivariate_from_csv(csv_path, date_column=None):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    if date_column and date_column in df.columns:\n",
        "        df[date_column] = pd.to_datetime(df[date_column])\n",
        "        df = df.sort_values(by=date_column)\n",
        "\n",
        "    features_df = df.select_dtypes(include=np.number)\n",
        "    if features_df.isnull().sum().sum() > 0:\n",
        "        features_df = features_df.fillna(method='ffill').fillna(method='bfill')\n",
        "        features_df = features_df.fillna(features_df.mean())\n",
        "\n",
        "    return features_df\n",
        "\n",
        "def train_from_csv(csv_path, feature_columns, target_column, date_column=None,\n",
        "                   seq_length=20, hidden_size=50, epochs=100,\n",
        "                   learning_rate=0.001, alpha=1.0, beta=1.0, n=1.0, graph=True):\n",
        "\n",
        "    all_data = load_multivariate_from_csv(csv_path, date_column=date_column)\n",
        "\n",
        "    feature_column_idx = [all_data.columns.get_loc(c) for c in feature_columns]\n",
        "    target_column_idx = all_data.columns.get_loc(target_column)\n",
        "\n",
        "    data_dict = prepare_multivariate_data(\n",
        "        all_data, seq_length=seq_length, feature_column_idx=feature_column_idx, target_column_idx=target_column_idx\n",
        "    )\n",
        "\n",
        "    model = MultivariateLSTM(\n",
        "        input_size=data_dict['input_size'], hidden_size=hidden_size,\n",
        "        output_size=data_dict['output_size'], alpha=alpha, beta=beta, n=n\n",
        "    )\n",
        "\n",
        "    test_rmse = train_model(model, data_dict['train_loader'], data_dict['test_loader'], epochs=epochs, learning_rate=learning_rate, verbose=graph)\n",
        "\n",
        "    if graph:\n",
        "        title = f'Forecasting {target_column} using {\",\".join(feature_columns)}'\n",
        "        predict_and_visualize_multivariate(model, data_dict, title=title)\n",
        "\n",
        "    return model, test_rmse\n",
        "#endregion\n",
        "\n",
        "#region ----------------- Lyapunov Exponent Calculation -----------------\n",
        "def compute_lyapunov_multivariate(initial_sequence, model, steps=1000, delta=1e-5):\n",
        "    seq_len, num_features = initial_sequence.shape\n",
        "    model.eval()\n",
        "\n",
        "    x0 = initial_sequence.reshape(1, seq_len, num_features).astype(np.float32)\n",
        "\n",
        "    perturb = np.random.randn(*x0.shape)\n",
        "    perturb /= np.linalg.norm(perturb)\n",
        "    x1 = x0 + perturb * delta\n",
        "    d0 = np.linalg.norm(x1 - x0)\n",
        "\n",
        "    divergences = []\n",
        "    for _ in range(steps):\n",
        "        with torch.no_grad():\n",
        "            x0_tensor = torch.tensor(x0, dtype=torch.float32, device=device)\n",
        "            x1_tensor = torch.tensor(x1, dtype=torch.float32, device=device)\n",
        "\n",
        "            y0 = model(x0_tensor).cpu().numpy().reshape(1, 1, -1) # Output shape (1, 1, output_size)\n",
        "            y1 = model(x1_tensor).cpu().numpy().reshape(1, 1, -1)\n",
        "\n",
        "        # Assuming output_size matches num_features for recurrence\n",
        "        if y0.shape[2] != num_features:\n",
        "            raise ValueError(f\"Model output size ({y0.shape[2]}) must match number of features ({num_features}) for Lyapunov calculation.\")\n",
        "\n",
        "        d = np.linalg.norm(y1 - y0)\n",
        "\n",
        "        if d > 1e-12:\n",
        "            divergences.append(np.log(d / d0))\n",
        "            # Renormalize\n",
        "            x1_pred_renorm = y0 + (d0 / d) * (y1 - y0)\n",
        "        else:\n",
        "            # Re-perturb if trajectories collapse\n",
        "            new_perturb = np.random.randn(*y0.shape)\n",
        "            new_perturb /= np.linalg.norm(new_perturb)\n",
        "            x1_pred_renorm = y0 + d0 * new_perturb\n",
        "\n",
        "        # Roll window\n",
        "        x0 = np.append(x0[:, 1:, :], y0, axis=1)\n",
        "        x1 = np.append(x1[:, 1:, :], x1_pred_renorm, axis=1)\n",
        "\n",
        "    divergences = np.array(divergences)\n",
        "    if len(divergences) < 2: return 0.0 # Not enough data for a fit\n",
        "\n",
        "    t_vals = np.arange(len(divergences))\n",
        "    coeffs = np.polyfit(t_vals, divergences, 1)\n",
        "    lyap = coeffs[0]\n",
        "\n",
        "    return lyap * 100 # Scaling for better numerical stability/readability\n",
        "#endregion\n",
        "\n",
        "#region ----------------- Pymoo Optimization Problem -----------------\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "CSV_PATH = 'lorenz5.csv'\n",
        "SEQ_LENGTH = 60\n",
        "HIDDEN_SIZE = 64\n",
        "EPOCHS = 1\n",
        "POPULATION_SIZE = 5\n",
        "GENERATIONS = 5\n",
        "\n",
        "# Load data once to get initial sequence for Lyapunov calculation\n",
        "FULL_DATA = load_multivariate_from_csv(CSV_PATH)\n",
        "FEATURE_COLS = ['x', 'y', 'z']\n",
        "TARGET_COL = ['x', 'y', 'z']\n",
        "INITIAL_SEQUENCE = FULL_DATA[FEATURE_COLS].values[:SEQ_LENGTH]\n",
        "\n",
        "\n",
        "class PymooProblem(Problem):\n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            n_var=3,          # Number of variables: alpha, beta, n\n",
        "            n_obj=2,          # Number of objectives: min RMSE, max Lyapunov\n",
        "            n_constr=0,       # Number of constraints\n",
        "            xl=np.array([-1.0, 0.1, 1]),   # Lower bounds for [alpha, beta, n]\n",
        "            xu=np.array([1.0, 2.0, 5])     # Upper bounds for [alpha, beta, n]\n",
        "        )\n",
        "\n",
        "    def _evaluate(self, x, out, *args, **kwargs):\n",
        "        # x is a 2D array where each row is a solution [alpha, beta, n]\n",
        "        objectives = []\n",
        "        for solution in x:\n",
        "            alpha, beta, n_float = solution\n",
        "            n_int = int(round(n_float)) # n must be an integer for the model\n",
        "\n",
        "            print(f\"Evaluating: α={alpha:.3f}, β={beta:.3f}, n={n_int}\")\n",
        "\n",
        "            # 1. Train the model\n",
        "            model, test_rmse = train_from_csv(\n",
        "                csv_path=CSV_PATH,\n",
        "                feature_columns=FEATURE_COLS,\n",
        "                target_column=TARGET_COL,\n",
        "                seq_length=SEQ_LENGTH,\n",
        "                hidden_size=HIDDEN_SIZE,\n",
        "                epochs=EPOCHS,\n",
        "                alpha=alpha,\n",
        "                beta=beta,\n",
        "                n=n_int,\n",
        "                graph=False # No plotting during optimization\n",
        "            )\n",
        "\n",
        "            # 2. Compute Lyapunov Exponent\n",
        "            lyap = compute_lyapunov_multivariate(INITIAL_SEQUENCE, model)\n",
        "\n",
        "            # Pymoo minimizes objectives, so we negate lyapunov to maximize it\n",
        "            objectives.append([test_rmse, -lyap])\n",
        "            print(f\"Result: RMSE={test_rmse:.4f}, Lyapunov={lyap:.4f}\")\n",
        "\n",
        "\n",
        "        out[\"F\"] = np.array(objectives)\n",
        "\n",
        "# --- ALGORITHM SETUP ---\n",
        "problem = PymooProblem()\n",
        "\n",
        "algorithm = NSGA2(\n",
        "    pop_size=POPULATION_SIZE,\n",
        "    n_offsprings=10,\n",
        "    sampling=FloatRandomSampling(),\n",
        "    crossover=SBX(prob=0.9, eta=15),\n",
        "    mutation=PM(eta=20),\n",
        "    eliminate_duplicates=True\n",
        ")\n",
        "\n",
        "termination = get_termination(\"n_gen\", GENERATIONS)\n",
        "\n",
        "# --- RUN OPTIMIZATION ---\n",
        "print(\"\\n--- Starting Pymoo NSGA-II Optimization ---\")\n",
        "res = minimize(\n",
        "    problem,\n",
        "    algorithm,\n",
        "    termination,\n",
        "    seed=1,\n",
        "    save_history=True,\n",
        "    verbose=True\n",
        ")\n",
        "print(\"--- Optimization Finished ---\")\n",
        "\n",
        "# --- PROCESS RESULTS ---\n",
        "# F is the objective space (results), X is the design space (parameters)\n",
        "F = res.F\n",
        "X = res.X\n",
        "\n",
        "# Find the best solution: the one with the lowest RMSE (first objective)\n",
        "best_solution_index = np.argmin(F[:, 0])\n",
        "best_params = X[best_solution_index]\n",
        "best_results = F[best_solution_index]\n",
        "\n",
        "best_alpha, best_beta, best_n_float = best_params\n",
        "best_n = int(round(best_n_float))\n",
        "best_rmse, neg_best_lyap = best_results\n",
        "\n",
        "print(\"\\n--- Best Parameters Found ---\")\n",
        "print(f\"Alpha: {best_alpha:.4f}\")\n",
        "print(f\"Beta: {best_beta:.4f}\")\n",
        "print(f\"N: {best_n}\")\n",
        "print(f\"Corresponding Test RMSE: {best_rmse:.4f}\")\n",
        "print(f\"Corresponding Lyapunov Exponent: {-neg_best_lyap:.4f}\")\n",
        "print(\"----------------------------\\n\")\n",
        "\n",
        "\n",
        "# --- RETRAIN AND VISUALIZE THE BEST MODEL ---\n",
        "print(\"--- Training final model with best parameters and visualizing... ---\")\n",
        "train_from_csv(\n",
        "    csv_path=CSV_PATH,\n",
        "    feature_columns=FEATURE_COLS,\n",
        "    target_column=TARGET_COL,\n",
        "    seq_length=SEQ_LENGTH,\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    epochs=EPOCHS,  # Train for longer on the best model\n",
        "    learning_rate=0.0005,\n",
        "    alpha=best_alpha,\n",
        "    beta=best_beta,\n",
        "    n=best_n,\n",
        "    graph=True # Enable graphing for the final run\n",
        ")\n",
        "#endregion"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: False\n",
            "\n",
            "--- Starting Pymoo NSGA-II Optimization ---\n",
            "Evaluating: α=-0.166, β=1.469, n=1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Model output size (1) must match number of features (3) for Lyapunov calculation.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3788582074.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;31m# --- RUN OPTIMIZATION ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- Starting Pymoo NSGA-II Optimization ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m res = minimize(\n\u001b[0m\u001b[1;32m    446\u001b[0m     \u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pymoo/optimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(problem, algorithm, termination, copy_algorithm, copy_termination, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# actually execute the algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# store the deep copied algorithm in the result object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pymoo/core/algorithm.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pymoo/core/algorithm.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m# call the advance with them after evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minfills\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfills\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfills\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfills\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pymoo/core/evaluator.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, problem, pop, skip_already_evaluated, evaluate_values_of, count_evals, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# do the actual evaluation - call the sub-function to set the corresponding values to the population\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_values_of\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# update the function evaluation counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pymoo/core/evaluator.py\u001b[0m in \u001b[0;36m_eval\u001b[0;34m(self, problem, pop, evaluate_values_of, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# call the problem to evaluate the solutions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_values_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_values_of\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_as_dictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# for each of the attributes set it to the problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pymoo/core/problem.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, X, return_values_of, return_as_dictionary, *args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# this is where the actual evaluation takes place\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0m_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_values_of\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pymoo/core/problem.py\u001b[0m in \u001b[0;36mdo\u001b[0;34m(self, X, return_values_of, *args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate_elementwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate_vectorized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# finally format the output dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pymoo/core/problem.py\u001b[0m in \u001b[0;36m_evaluate_vectorized\u001b[0;34m(self, X, out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate_vectorized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate_elementwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3788582074.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, x, out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0;31m# 2. Compute Lyapunov Exponent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mlyap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_lyapunov_multivariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINITIAL_SEQUENCE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;31m# Pymoo minimizes objectives, so we negate lyapunov to maximize it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3788582074.py\u001b[0m in \u001b[0;36mcompute_lyapunov_multivariate\u001b[0;34m(initial_sequence, model, steps, delta)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;31m# Assuming output_size matches num_features for recurrence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model output size ({y0.shape[2]}) must match number of features ({num_features}) for Lyapunov calculation.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Model output size (1) must match number of features (3) for Lyapunov calculation."
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "v-eVpraILobD",
        "outputId": "73e31dc0-5911-4ebf-9914-44a20b430b68"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}