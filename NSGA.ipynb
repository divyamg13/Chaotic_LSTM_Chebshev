{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pymoo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-xE_GVVLrnP",
        "outputId": "41c0ef71-2b4d-4af4-b2d5-ccb479aaab41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymoo in /usr/local/lib/python3.12/dist-packages (0.6.1.5)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.12/dist-packages (from pymoo) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.12/dist-packages (from pymoo) (1.16.2)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.12/dist-packages (from pymoo) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.4 in /usr/local/lib/python3.12/dist-packages (from pymoo) (1.8.0)\n",
            "Requirement already satisfied: cma>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from pymoo) (4.4.0)\n",
            "Requirement already satisfied: alive-progress in /usr/local/lib/python3.12/dist-packages (from pymoo) (3.3.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from pymoo) (0.3.8)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.12/dist-packages (from pymoo) (1.2.18)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (2.9.0.post0)\n",
            "Requirement already satisfied: about-time==4.2.1 in /usr/local/lib/python3.12/dist-packages (from alive-progress->pymoo) (4.2.1)\n",
            "Requirement already satisfied: graphemeu==0.7.2 in /usr/local/lib/python3.12/dist-packages (from alive-progress->pymoo) (0.7.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.12/dist-packages (from Deprecated->pymoo) (1.17.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3->pymoo) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import math\n",
        "import copy\n",
        "import warnings\n",
        "\n",
        "# Suppress matplotlib warnings for cleaner output during optimization\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
        "\n",
        "# --- Pymoo Imports ---\n",
        "from pymoo.core.problem import Problem\n",
        "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
        "from pymoo.operators.crossover.sbx import SBX\n",
        "from pymoo.operators.mutation.pm import PM\n",
        "from pymoo.operators.sampling.rnd import FloatRandomSampling\n",
        "from pymoo.termination import get_termination\n",
        "from pymoo.optimize import minimize\n",
        "\n",
        "\n",
        "# Set device to GPU if available, otherwise CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "#region ----------------- Model Architecture -----------------\n",
        "class ChebySigmoidActivation(nn.Module):\n",
        "    def __init__(self, alpha=1.0, beta=1.0, n=1.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.n = n\n",
        "\n",
        "    def get_n_value(self):\n",
        "        return self.n\n",
        "\n",
        "    def forward(self, x):\n",
        "        sigmoid_val = torch.sigmoid(x)\n",
        "        tanh_beta_val = torch.tanh(self.beta * x)\n",
        "        safe_tanh_beta_val = torch.clamp(tanh_beta_val, -1 + 1e-6, 1 - 1e-6)\n",
        "        out = sigmoid_val + self.alpha * torch.cos(self.n * torch.acos(safe_tanh_beta_val)) * sigmoid_val * (1 - sigmoid_val)\n",
        "        return out\n",
        "\n",
        "class ChebyTanhActivation(nn.Module):\n",
        "    def __init__(self, alpha=1.0, beta=1.0, n=1.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.n = n\n",
        "\n",
        "    def get_n_value(self):\n",
        "        return self.n\n",
        "\n",
        "    def forward(self, x):\n",
        "        tanh_beta_val = torch.tanh(self.beta * x)\n",
        "        tanh_val = torch.tanh(x)\n",
        "        sech_val = (1 / torch.cosh(x)) ** 2\n",
        "        safe_tanh_beta_val = torch.clamp(tanh_beta_val, -1 + 1e-6, 1 - 1e-6)\n",
        "        out = tanh_val + self.alpha * torch.cos(self.n * torch.acos(safe_tanh_beta_val)) * sech_val\n",
        "        return out\n",
        "\n",
        "class CustomLSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, alpha=1.0, beta=1.0, n=1.0):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.weight_ih = nn.Parameter(torch.empty(4 * hidden_size, input_size))\n",
        "        self.weight_hh = nn.Parameter(torch.empty(4 * hidden_size, hidden_size))\n",
        "        self.bias_ih = nn.Parameter(torch.zeros(4 * hidden_size))\n",
        "        self.bias_hh = nn.Parameter(torch.zeros(4 * hidden_size))\n",
        "        self.sigmoid_activation = ChebySigmoidActivation(alpha=alpha, beta=beta, n=n)\n",
        "        self.tanh_activation = ChebyTanhActivation(alpha=alpha, beta=beta, n=n)\n",
        "\n",
        "    def forward(self, input, hx):\n",
        "        h_prev, c_prev = hx\n",
        "        gates = F.linear(input, self.weight_ih, self.bias_ih) + F.linear(h_prev, self.weight_hh, self.bias_hh)\n",
        "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, dim=1)\n",
        "        forgetgate = self.sigmoid_activation(forgetgate)\n",
        "        ingate = self.sigmoid_activation(ingate)\n",
        "        cellgate_candidate = self.tanh_activation(cellgate)\n",
        "        outgate = self.sigmoid_activation(outgate)\n",
        "        c_next = forgetgate * c_prev + ingate * cellgate_candidate\n",
        "        h_next = outgate * self.tanh_activation(c_next)\n",
        "        return h_next, (h_next, c_next)\n",
        "\n",
        "    def get_n_values(self):\n",
        "        return {\n",
        "            'sigmoid_n': self.sigmoid_activation.get_n_value(),\n",
        "            'tanh_n': self.tanh_activation.get_n_value()\n",
        "        }\n",
        "\n",
        "class CustomLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, alpha=1.0, beta=1.0, n=1.0):\n",
        "        super().__init__()\n",
        "        self.cell = CustomLSTMCell(input_size, hidden_size, alpha=alpha, beta=beta, n=n)\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    def forward(self, inputs, hx=None):\n",
        "        inputs = inputs.transpose(0, 1)\n",
        "        if hx is None:\n",
        "            batch_size = inputs.size(1)\n",
        "            h_0 = torch.zeros(batch_size, self.cell.hidden_size, device=inputs.device)\n",
        "            c_0 = torch.zeros(batch_size, self.cell.hidden_size, device=inputs.device)\n",
        "            hx = (h_0, c_0)\n",
        "        h, c = hx\n",
        "        outputs = []\n",
        "        for t in range(inputs.size(0)):\n",
        "            h, (h, c) = self.cell(inputs[t], (h, c))\n",
        "            outputs.append(h)\n",
        "        outputs = torch.stack(outputs).transpose(0, 1)\n",
        "        return outputs, (h, c)\n",
        "\n",
        "    def get_n_values(self):\n",
        "        return self.cell.get_n_values()\n",
        "\n",
        "class MultivariateLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=50, output_size=1, alpha=1.0, beta=1.0, n=1.0):\n",
        "        super().__init__()\n",
        "        self.lstm = CustomLSTM(input_size, hidden_size, alpha=alpha, beta=beta, n=n)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.linear = nn.Linear(hidden_size, output_size)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None: init.constant_(module.bias, 0)\n",
        "        elif isinstance(module, CustomLSTMCell):\n",
        "            init.xavier_uniform_(module.weight_ih)\n",
        "            init.xavier_uniform_(module.weight_hh)\n",
        "            init.constant_(module.bias_ih, 0)\n",
        "            init.constant_(module.bias_hh, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        last_output = self.dropout(lstm_out[:, -1, :])\n",
        "        predictions = self.linear(last_output)\n",
        "        return predictions\n",
        "\n",
        "    def get_n_values(self):\n",
        "        return self.lstm.get_n_values()\n",
        "#endregion\n",
        "\n",
        "#region ----------------- Data & Training Pipeline -----------------\n",
        "def create_multivariate_sequences(data, seq_length, feature_column_idx=None, target_column_idx=None):\n",
        "    xs, ys = [], []\n",
        "    if feature_column_idx is not None and not isinstance(feature_column_idx, list):\n",
        "        feature_column_idx = [feature_column_idx]\n",
        "    for i in range(len(data) - seq_length):\n",
        "        x = data[i:i+seq_length, feature_column_idx] if feature_column_idx is not None else data[i:i+seq_length]\n",
        "        y = data[i+seq_length, target_column_idx] if target_column_idx is not None else data[i+seq_length]\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "def prepare_multivariate_data(data, seq_length=20, train_ratio=0.8, batch_size=32, feature_column_idx=None, target_column_idx=None):\n",
        "    if isinstance(data, pd.DataFrame):\n",
        "        data = data.values\n",
        "\n",
        "    n_features = data.shape[1]\n",
        "    input_size = len(feature_column_idx) if isinstance(feature_column_idx, list) else (1 if feature_column_idx is not None else n_features)\n",
        "    output_size = len(target_column_idx) if isinstance(target_column_idx, list) else (1 if target_column_idx is not None else n_features)\n",
        "\n",
        "    train_size = int(len(data) * train_ratio)\n",
        "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "    scaler.fit(data[:train_size])\n",
        "    data_scaled = scaler.transform(data)\n",
        "\n",
        "    X, y = create_multivariate_sequences(data_scaled, seq_length, feature_column_idx, target_column_idx)\n",
        "\n",
        "    X_train, X_test = X[:train_size-seq_length], X[train_size-seq_length:]\n",
        "    y_train, y_test = y[:train_size-seq_length], y[train_size-seq_length:]\n",
        "\n",
        "    X_train = torch.FloatTensor(X_train).to(device)\n",
        "    y_train = torch.FloatTensor(y_train).to(device)\n",
        "    X_test = torch.FloatTensor(X_test).to(device)\n",
        "    y_test = torch.FloatTensor(y_test).to(device)\n",
        "\n",
        "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return {\n",
        "        'train_loader': train_loader, 'test_loader': test_loader, 'scaler': scaler,\n",
        "        'X_train': X_train, 'y_train': y_train, 'X_test': X_test, 'y_test': y_test,\n",
        "        'input_size': input_size, 'output_size': output_size,\n",
        "        'target_column_idx': target_column_idx\n",
        "    }\n",
        "\n",
        "def train_model(model, train_loader, test_loader, epochs=100, learning_rate=0.001, verbose=True):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(X_batch)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        if verbose and (epoch + 1) % 10 == 0:\n",
        "            model.eval()\n",
        "            test_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for X_test_batch, y_test_batch in test_loader:\n",
        "                    y_pred_test = model(X_test_batch)\n",
        "                    test_loss += criterion(y_pred_test, y_test_batch).item()\n",
        "            test_loss /= len(test_loader)\n",
        "            print(f'Epoch {epoch+1}/{epochs}, Test Loss: {test_loss:.6f}')\n",
        "\n",
        "    # Final evaluation to get test RMSE\n",
        "    model.eval()\n",
        "    all_preds, all_true = [], []\n",
        "    with torch.no_grad():\n",
        "        for X_test_batch, y_test_batch in test_loader:\n",
        "            preds = model(X_test_batch).cpu().numpy()\n",
        "            true = y_test_batch.cpu().numpy()\n",
        "            all_preds.append(preds)\n",
        "            all_true.append(true)\n",
        "\n",
        "    test_rmse = sqrt(mean_squared_error(np.vstack(all_true), np.vstack(all_preds)))\n",
        "    return test_rmse\n",
        "\n",
        "def predict_all_data(model, data_dict, target_cols_to_predict=None):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_predictions_scaled = model(data_dict['X_test']).cpu().numpy()\n",
        "\n",
        "    scaler = data_dict['scaler']\n",
        "    all_target_idx = data_dict['target_column_idx']\n",
        "    all_target_cols = [data_dict['scaler'].get_feature_names_out()[i] for i in all_target_idx]\n",
        "\n",
        "    # Default to first column if nothing is specified\n",
        "    if target_cols_to_predict is None:\n",
        "        target_cols_to_predict = [all_target_cols[0]]\n",
        "\n",
        "    # Find the indices within the output that we want to keep\n",
        "    predict_indices_in_output = [all_target_cols.index(col) for col in target_cols_to_predict]\n",
        "\n",
        "    # Create a full-size array for inverse transform\n",
        "    dummy_array = np.zeros((test_predictions_scaled.shape[0], scaler.n_features_in_))\n",
        "    # Place all predictions into their correct spots\n",
        "    dummy_array[:, all_target_idx] = test_predictions_scaled\n",
        "    # Inverse transform the whole array\n",
        "    predictions_unscaled_all = scaler.inverse_transform(dummy_array)\n",
        "\n",
        "    # Select only the columns we want to return\n",
        "    final_predictions = predictions_unscaled_all[:, [all_target_idx[i] for i in predict_indices_in_output]]\n",
        "\n",
        "    return final_predictions\n",
        "\n",
        "def predict_and_visualize_multivariate(model, data_dict, title='Multivariate Time Series Forecasting', target_cols_to_plot=None):\n",
        "    scaler = data_dict['scaler']\n",
        "    all_target_idx = data_dict['target_column_idx']\n",
        "    all_target_cols = [scaler.get_feature_names_out()[i] for i in all_target_idx]\n",
        "    y_test_numpy = data_dict['y_test'].cpu().numpy()\n",
        "\n",
        "    # Default to first column if nothing is specified\n",
        "    if target_cols_to_plot is None:\n",
        "        target_cols_to_plot = [all_target_cols[0]]\n",
        "\n",
        "    predictions = predict_all_data(model, data_dict, target_cols_to_predict=target_cols_to_plot)\n",
        "\n",
        "    # Get actual data for the same columns\n",
        "    plot_indices_in_output = [all_target_cols.index(col) for col in target_cols_to_plot]\n",
        "    dummy_array_true = np.zeros((len(y_test_numpy), scaler.n_features_in_))\n",
        "    dummy_array_true[:, all_target_idx] = y_test_numpy\n",
        "    actual = scaler.inverse_transform(dummy_array_true)[:, [all_target_idx[i] for i in plot_indices_in_output]]\n",
        "\n",
        "    # --- Plotting ---\n",
        "    plt.figure(figsize=(15, 7))\n",
        "    colors = plt.cm.viridis(np.linspace(0, 1, len(target_cols_to_plot)))\n",
        "\n",
        "    for i, col_name in enumerate(target_cols_to_plot):\n",
        "        plt.plot(actual[:, i], label=f'Actual {col_name}', color=colors[i], alpha=0.8)\n",
        "        plt.plot(predictions[:, i], label=f'Predicted {col_name}', color=colors[i], linestyle='--')\n",
        "\n",
        "    test_rmse = sqrt(mean_squared_error(actual, predictions))\n",
        "    plt.title(f'{title} - Test Set (Overall RMSE: {test_rmse:.4f})')\n",
        "    plt.xlabel('Time Step')\n",
        "    plt.ylabel('Value')\n",
        "    plt.legend()\n",
        "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return test_rmse\n",
        "\n",
        "def load_multivariate_from_csv(csv_path, date_column=None):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    if date_column and date_column in df.columns:\n",
        "        df[date_column] = pd.to_datetime(df[date_column])\n",
        "        df = df.sort_values(by=date_column)\n",
        "\n",
        "    features_df = df.select_dtypes(include=np.number)\n",
        "    if features_df.isnull().sum().sum() > 0:\n",
        "        features_df = features_df.fillna(method='ffill').fillna(method='bfill')\n",
        "        features_df = features_df.fillna(features_df.mean())\n",
        "\n",
        "    return features_df\n",
        "\n",
        "def train_from_csv(csv_path, feature_columns, target_column, date_column=None,\n",
        "                   seq_length=20, hidden_size=50, epochs=100,\n",
        "                   learning_rate=0.001, alpha=1.0, beta=1.0, n=1.0, graph=True):\n",
        "\n",
        "    all_data = load_multivariate_from_csv(csv_path, date_column=date_column)\n",
        "\n",
        "    feature_column_idx = [all_data.columns.get_loc(c) for c in feature_columns]\n",
        "    target_column_idx = [all_data.columns.get_loc(c) for c in target_column] if isinstance(target_column, list) else all_data.columns.get_loc(target_column)\n",
        "\n",
        "    data_dict = prepare_multivariate_data(\n",
        "        all_data, seq_length=seq_length, feature_column_idx=feature_column_idx, target_column_idx=target_column_idx\n",
        "    )\n",
        "\n",
        "    model = MultivariateLSTM(\n",
        "        input_size=data_dict['input_size'], hidden_size=hidden_size,\n",
        "        output_size=data_dict['output_size'], alpha=alpha, beta=beta, n=n\n",
        "    )\n",
        "\n",
        "    test_rmse = train_model(model, data_dict['train_loader'], data_dict['test_loader'], epochs=epochs, learning_rate=learning_rate, verbose=graph)\n",
        "\n",
        "    if graph:\n",
        "      target_str = \", \".join(target_column) if isinstance(target_column, list) else target_column\n",
        "      title = f'Forecasting {target_str} using {\",\".join(feature_columns)}'\n",
        "      predict_and_visualize_multivariate(model, data_dict, title=title, target_cols_to_plot=target_column)\n",
        "\n",
        "    return model, test_rmse\n",
        "#endregion\n",
        "\n",
        "#region ----------------- Lyapunov Exponent Calculation -----------------\n",
        "def compute_lyapunov_multivariate(initial_sequence, model, steps=1000, delta=1e-5):\n",
        "    seq_len, num_features = initial_sequence.shape\n",
        "    model.eval()\n",
        "\n",
        "    x0 = initial_sequence.reshape(1, seq_len, num_features).astype(np.float32)\n",
        "\n",
        "    perturb = np.random.randn(*x0.shape)\n",
        "    perturb /= np.linalg.norm(perturb)\n",
        "    x1 = x0 + perturb * delta\n",
        "    d0 = np.linalg.norm(x1 - x0)\n",
        "\n",
        "    divergences = []\n",
        "    for _ in range(steps):\n",
        "        with torch.no_grad():\n",
        "            x0_tensor = torch.tensor(x0, dtype=torch.float32, device=device)\n",
        "            x1_tensor = torch.tensor(x1, dtype=torch.float32, device=device)\n",
        "\n",
        "            y0 = model(x0_tensor).cpu().numpy().reshape(1, 1, -1) # Output shape (1, 1, output_size)\n",
        "            y1 = model(x1_tensor).cpu().numpy().reshape(1, 1, -1)\n",
        "\n",
        "        # Assuming output_size matches num_features for recurrence\n",
        "        if y0.shape[2] != num_features:\n",
        "            raise ValueError(f\"Model output size ({y0.shape[2]}) must match number of features ({num_features}) for Lyapunov calculation.\")\n",
        "\n",
        "        d = np.linalg.norm(y1 - y0)\n",
        "\n",
        "        if d > 1e-12:\n",
        "            divergences.append(np.log(d / d0))\n",
        "            # Renormalize\n",
        "            x1_pred_renorm = y0 + (d0 / d) * (y1 - y0)\n",
        "        else:\n",
        "            # Re-perturb if trajectories collapse\n",
        "            new_perturb = np.random.randn(*y0.shape)\n",
        "            new_perturb /= np.linalg.norm(new_perturb)\n",
        "            x1_pred_renorm = y0 + d0 * new_perturb\n",
        "\n",
        "        # Roll window\n",
        "        x0 = np.append(x0[:, 1:, :], y0, axis=1)\n",
        "        x1 = np.append(x1[:, 1:, :], x1_pred_renorm, axis=1)\n",
        "\n",
        "    divergences = np.array(divergences)\n",
        "    if len(divergences) < 2: return 0.0 # Not enough data for a fit\n",
        "\n",
        "    t_vals = np.arange(len(divergences))\n",
        "    coeffs = np.polyfit(t_vals, divergences, 1)\n",
        "    lyap = coeffs[0]\n",
        "\n",
        "    return lyap * 100 # Scaling for better numerical stability/readability\n",
        "#endregion\n",
        "\n",
        "#region ----------------- Pymoo Optimization Problem -----------------\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "CSV_PATH = 'lorenz5.csv'\n",
        "SEQ_LENGTH = 60\n",
        "HIDDEN_SIZE = 64\n",
        "EPOCHS = 1\n",
        "POPULATION_SIZE = 5\n",
        "GENERATIONS = 5\n",
        "\n",
        "# Load data once to get initial sequence for Lyapunov calculation\n",
        "FULL_DATA = load_multivariate_from_csv(CSV_PATH)\n",
        "FEATURE_COLS = ['x', 'y', 'z']\n",
        "TARGET_COL = ['x', 'y', 'z']\n",
        "INITIAL_SEQUENCE = FULL_DATA[FEATURE_COLS].values[:SEQ_LENGTH]\n",
        "\n",
        "\n",
        "class PymooProblem(Problem):\n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            n_var=3,          # Number of variables: alpha, beta, n\n",
        "            n_obj=2,          # Number of objectives: min RMSE, max Lyapunov\n",
        "            n_constr=0,       # Number of constraints\n",
        "            xl=np.array([-1.0, 0.1, 1]),   # Lower bounds for [alpha, beta, n]\n",
        "            xu=np.array([1.0, 2.0, 5])     # Upper bounds for [alpha, beta, n]\n",
        "        )\n",
        "\n",
        "    def _evaluate(self, x, out, *args, **kwargs):\n",
        "        # x is a 2D array where each row is a solution [alpha, beta, n]\n",
        "        objectives = []\n",
        "        for solution in x:\n",
        "            alpha, beta, n_float = solution\n",
        "            n_int = int(round(n_float)) # n must be an integer for the model\n",
        "\n",
        "            print(f\"Evaluating: α={alpha:.3f}, β={beta:.3f}, n={n_int}\")\n",
        "\n",
        "            # 1. Train the model\n",
        "            model, test_rmse = train_from_csv(\n",
        "                csv_path=CSV_PATH,\n",
        "                feature_columns=FEATURE_COLS,\n",
        "                target_column=TARGET_COL,\n",
        "                seq_length=SEQ_LENGTH,\n",
        "                hidden_size=HIDDEN_SIZE,\n",
        "                epochs=EPOCHS,\n",
        "                alpha=alpha,\n",
        "                beta=beta,\n",
        "                n=n_int,\n",
        "                graph=False # No plotting during optimization\n",
        "            )\n",
        "\n",
        "            # 2. Compute Lyapunov Exponent\n",
        "            lyap = compute_lyapunov_multivariate(INITIAL_SEQUENCE, model)\n",
        "\n",
        "            # Pymoo minimizes objectives, so we negate lyapunov to maximize it\n",
        "            objectives.append([test_rmse, -lyap])\n",
        "            print(f\"Result: RMSE={test_rmse:.4f}, Lyapunov={lyap:.4f}\")\n",
        "\n",
        "\n",
        "        out[\"F\"] = np.array(objectives)\n",
        "\n",
        "# --- ALGORITHM SETUP ---\n",
        "problem = PymooProblem()\n",
        "\n",
        "algorithm = NSGA2(\n",
        "    pop_size=POPULATION_SIZE,\n",
        "    n_offsprings=10,\n",
        "    sampling=FloatRandomSampling(),\n",
        "    crossover=SBX(prob=0.9, eta=15),\n",
        "    mutation=PM(eta=20),\n",
        "    eliminate_duplicates=True\n",
        ")\n",
        "\n",
        "termination = get_termination(\"n_gen\", GENERATIONS)\n",
        "\n",
        "# --- RUN OPTIMIZATION ---\n",
        "print(\"\\n--- Starting Pymoo NSGA-II Optimization ---\")\n",
        "res = minimize(\n",
        "    problem,\n",
        "    algorithm,\n",
        "    termination,\n",
        "    seed=1,\n",
        "    save_history=True,\n",
        "    verbose=True\n",
        ")\n",
        "print(\"--- Optimization Finished ---\")\n",
        "\n",
        "# --- PROCESS RESULTS ---\n",
        "# F is the objective space (results), X is the design space (parameters)\n",
        "F = res.F\n",
        "X = res.X\n",
        "\n",
        "# Find the best solution: the one with the lowest RMSE (first objective)\n",
        "best_solution_index = np.argmin(F[:, 0])\n",
        "best_params = X[best_solution_index]\n",
        "best_results = F[best_solution_index]\n",
        "\n",
        "best_alpha, best_beta, best_n_float = best_params\n",
        "best_n = int(round(best_n_float))\n",
        "best_rmse, neg_best_lyap = best_results\n",
        "\n",
        "print(\"\\n--- Best Parameters Found ---\")\n",
        "print(f\"Alpha: {best_alpha:.4f}\")\n",
        "print(f\"Beta: {best_beta:.4f}\")\n",
        "print(f\"N: {best_n}\")\n",
        "print(f\"Corresponding Test RMSE: {best_rmse:.4f}\")\n",
        "print(f\"Corresponding Lyapunov Exponent: {-neg_best_lyap:.4f}\")\n",
        "print(\"----------------------------\\n\")\n",
        "\n",
        "\n",
        "# --- RETRAIN AND VISUALIZE THE BEST MODEL ---\n",
        "print(\"--- Training final model with best parameters and visualizing... ---\")\n",
        "train_from_csv(\n",
        "    csv_path=CSV_PATH,\n",
        "    feature_columns=FEATURE_COLS,\n",
        "    target_column=TARGET_COL,\n",
        "    seq_length=SEQ_LENGTH,\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    epochs=EPOCHS,  # Train for longer on the best model\n",
        "    learning_rate=0.0005,\n",
        "    alpha=best_alpha,\n",
        "    beta=best_beta,\n",
        "    n=best_n,\n",
        "    graph=True # Enable graphing for the final run\n",
        ")\n",
        "#endregion"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: False\n",
            "\n",
            "--- Starting Pymoo NSGA-II Optimization ---\n",
            "Evaluating: α=-0.166, β=1.469, n=1\n",
            "Result: RMSE=0.0291, Lyapunov=0.0121\n",
            "Evaluating: α=-0.395, β=0.379, n=1\n",
            "Result: RMSE=0.0118, Lyapunov=-0.0004\n",
            "Evaluating: α=-0.627, β=0.757, n=3\n",
            "Result: RMSE=0.0408, Lyapunov=0.0086\n",
            "Evaluating: α=0.078, β=0.896, n=4\n",
            "Result: RMSE=0.0171, Lyapunov=0.0090\n",
            "Evaluating: α=-0.591, β=1.768, n=1\n",
            "Result: RMSE=0.3574, Lyapunov=-0.0404\n",
            "==========================================================\n",
            "n_gen  |  n_eval  | n_nds  |      eps      |   indicator  \n",
            "==========================================================\n",
            "     1 |        5 |      3 |             - |             -\n",
            "Evaluating: α=-0.166, β=1.346, n=1\n",
            "Result: RMSE=0.0127, Lyapunov=0.0150\n",
            "Evaluating: α=-0.395, β=0.407, n=1\n",
            "Result: RMSE=0.0137, Lyapunov=0.0046\n",
            "Evaluating: α=-0.172, β=0.455, n=1\n",
            "Result: RMSE=0.0200, Lyapunov=0.0067\n",
            "Evaluating: α=0.182, β=1.469, n=1\n",
            "Result: RMSE=0.0262, Lyapunov=0.0033\n",
            "Evaluating: α=-0.404, β=1.060, n=1\n",
            "Result: RMSE=0.0341, Lyapunov=0.0019\n",
            "Evaluating: α=-0.395, β=0.379, n=1\n",
            "Result: RMSE=0.0152, Lyapunov=0.0109\n",
            "Evaluating: α=-0.389, β=1.376, n=1\n",
            "Result: RMSE=0.0584, Lyapunov=-0.0033\n",
            "Evaluating: α=-0.627, β=0.757, n=3\n",
            "Result: RMSE=0.0289, Lyapunov=0.0108\n",
            "Evaluating: α=0.064, β=0.378, n=4\n",
            "Result: RMSE=0.0175, Lyapunov=0.0111\n",
            "Evaluating: α=-0.297, β=0.378, n=2\n",
            "Result: RMSE=0.0251, Lyapunov=0.0062\n",
            "     2 |       15 |      2 |  0.1882509226 |         ideal\n",
            "Evaluating: α=-0.173, β=0.379, n=1\n",
            "Result: RMSE=0.0158, Lyapunov=0.0114\n",
            "Evaluating: α=-0.288, β=1.292, n=1\n",
            "Result: RMSE=0.0264, Lyapunov=0.0095\n",
            "Evaluating: α=-0.395, β=1.307, n=1\n",
            "Result: RMSE=0.0609, Lyapunov=0.0130\n",
            "Evaluating: α=-0.166, β=1.346, n=2\n",
            "Result: RMSE=0.0173, Lyapunov=0.0105\n",
            "Evaluating: α=-0.295, β=1.135, n=1\n",
            "Result: RMSE=0.0263, Lyapunov=-0.0050\n",
            "Evaluating: α=-0.075, β=0.433, n=1\n",
            "Result: RMSE=0.0116, Lyapunov=0.0105\n",
            "Evaluating: α=-0.395, β=0.379, n=1\n",
            "Result: RMSE=0.0104, Lyapunov=0.0170\n",
            "Evaluating: α=-0.166, β=0.453, n=1\n",
            "Result: RMSE=0.0199, Lyapunov=0.0139\n",
            "Evaluating: α=-0.395, β=0.324, n=1\n",
            "Result: RMSE=0.0153, Lyapunov=0.0097\n",
            "Evaluating: α=-0.199, β=1.346, n=1\n",
            "Result: RMSE=0.0142, Lyapunov=0.0132\n",
            "     3 |       25 |      1 |  0.0174455502 |         nadir\n",
            "Evaluating: α=-0.154, β=0.363, n=1\n",
            "Result: RMSE=0.0132, Lyapunov=0.0121\n",
            "Evaluating: α=0.028, β=0.433, n=1\n",
            "Result: RMSE=0.0168, Lyapunov=0.0119\n",
            "Evaluating: α=-0.166, β=1.346, n=1\n",
            "Result: RMSE=0.0129, Lyapunov=0.0240\n",
            "Evaluating: α=-0.412, β=0.433, n=1\n",
            "Result: RMSE=0.0197, Lyapunov=0.0180\n",
            "Evaluating: α=-0.407, β=1.362, n=1\n",
            "Result: RMSE=0.0646, Lyapunov=0.0043\n",
            "Evaluating: α=-0.370, β=0.408, n=1\n",
            "Result: RMSE=0.0197, Lyapunov=0.0129\n",
            "Evaluating: α=-0.369, β=0.379, n=1\n",
            "Result: RMSE=0.0269, Lyapunov=0.0092\n",
            "Evaluating: α=-0.166, β=1.346, n=1\n",
            "Result: RMSE=0.0201, Lyapunov=0.0085\n",
            "Evaluating: α=-0.090, β=0.508, n=1\n",
            "Result: RMSE=0.0133, Lyapunov=0.0113\n",
            "Evaluating: α=-0.395, β=0.433, n=1\n",
            "Result: RMSE=0.0142, Lyapunov=0.0159\n",
            "     4 |       35 |      2 |  1.0000000000 |         ideal\n",
            "Evaluating: α=-0.395, β=1.361, n=1\n",
            "Result: RMSE=0.0622, Lyapunov=0.0043\n",
            "Evaluating: α=-0.166, β=0.379, n=1\n",
            "Result: RMSE=0.0140, Lyapunov=0.0097\n",
            "Evaluating: α=-0.414, β=0.433, n=1\n",
            "Result: RMSE=0.0138, Lyapunov=0.0118\n",
            "Evaluating: α=-0.396, β=0.506, n=1\n",
            "Result: RMSE=0.0136, Lyapunov=0.0122\n",
            "Evaluating: α=-0.170, β=0.388, n=1\n",
            "Result: RMSE=0.0158, Lyapunov=0.0151\n",
            "Evaluating: α=-0.166, β=0.364, n=1\n",
            "Result: RMSE=0.0160, Lyapunov=0.0154\n",
            "Evaluating: α=-0.552, β=1.346, n=1\n",
            "Result: RMSE=0.1697, Lyapunov=0.0054\n",
            "Evaluating: α=-0.184, β=1.386, n=1\n",
            "Result: RMSE=0.0226, Lyapunov=0.0088\n",
            "Evaluating: α=-0.412, β=0.433, n=1\n",
            "Result: RMSE=0.0142, Lyapunov=0.0075\n",
            "Evaluating: α=-0.391, β=1.288, n=1\n",
            "Result: RMSE=0.0609, Lyapunov=0.0068\n",
            "     5 |       45 |      2 |  0.000000E+00 |             f\n",
            "--- Optimization Finished ---\n",
            "\n",
            "--- Best Parameters Found ---\n",
            "Alpha: -0.3953\n",
            "Beta: 0.3788\n",
            "N: 1\n",
            "Corresponding Test RMSE: 0.0104\n",
            "Corresponding Lyapunov Exponent: 0.0170\n",
            "----------------------------\n",
            "\n",
            "--- Training final model with best parameters and visualizing... ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'linear'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2743876940.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;31m# --- RETRAIN AND VISUALIZE THE BEST MODEL ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Training final model with best parameters and visualizing... ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m train_from_csv(\n\u001b[0m\u001b[1;32m    506\u001b[0m     \u001b[0mcsv_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCSV_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0mfeature_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFEATURE_COLS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2743876940.py\u001b[0m in \u001b[0;36mtrain_from_csv\u001b[0;34m(csv_path, feature_columns, target_column, date_column, seq_length, hidden_size, epochs, learning_rate, alpha, beta, n, graph)\u001b[0m\n\u001b[1;32m    331\u001b[0m     )\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m     \u001b[0mtest_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loader'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_loader'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2743876940.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, epochs, learning_rate, verbose)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2743876940.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mlast_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2743876940.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hx)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2743876940.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mh_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mgates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_ih\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mingate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforgetgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcellgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mforgetgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforgetgate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'linear'"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v-eVpraILobD",
        "outputId": "f05f4c4d-71bc-4483-9561-7717bc54af88"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}